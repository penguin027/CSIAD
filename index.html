<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Visual Instruction Tuning">
  <meta name="keywords" content="multimodal chatbot">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CSIAD</title>
  <style>
    #painting_icon {
      position: relative;
      top: -20px; /* 调整此值以控制图片上移的程度 */
      margin-left: 5px; /* 调整此值以控制图片与文字之间的间距 */
    }
    #painting_icon2 {
      position: relative;
      top: -20px; /* 调整此值以控制图片上移的程度 */
      margin-left: 0px; /* 调整此值以控制图片与文字之间的间距 */
    }
  </style>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="images/icon.png">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/js/all.min.js"></script>
  <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.16.0/gradio.js"></script>

  <style>
    .expandable-card .card-text-container {
        max-height: 200px;
        overflow-y: hidden;
        position: relative;
    }
    .expandable-card.expanded .card-text-container {
        max-height: none;
    }
    .expand-btn {
        position: relative;
        display: none;
        background-color: rgba(255, 255, 255, 0.8);
        color: #510c75;
        border-color: transparent;
    }
    .expand-btn:hover {
        background-color: rgba(200, 200, 200, 0.8);
        text-decoration: none;
        border-color: transparent;
        color: #510c75;
    }
    .expand-btn:focus {
        outline: none;
        text-decoration: none;
    }
    .expandable-card:not(.expanded) .card-text-container:after {
        content: "";
        position: absolute;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 90px;
        background: linear-gradient(rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 1));
    }
    .expandable-card:not(.expanded) .expand-btn {
        margin-top: -40px;
    }
    .card-body {
        padding-bottom: 5px;
    }
    .vertical-flex-layout {
        justify-content: center;
        align-items: center;
        height: 100%;
        display: flex;
        flex-direction: column;
        gap: 5px;
    }
    .figure-img {
        max-width: 100%;
        height: auto;
    }
    .adjustable-font-size {
        font-size: calc(0.5rem + 2vw);
    }
    .chat-history {
        flex-grow: 1;
        overflow-y: auto;
        padding: 5px;
        border-bottom: 1px solid #ccc;
        margin-bottom: 10px;
    }
    #gradio pre {
        background-color: transparent;
    }
    /* 独特命名空间的滑动窗口样式 */
/* 独特命名空间的滑动窗口样式 */
.image-slider {
  position: relative;
  width: 100%; /* 调整宽度 */
  max-width: 5000px; /* 调整最大宽度 */

  overflow: hidden;
  border-radius: 10px;
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
  margin: 20px auto;
}

.image-slider .slides {
  display: flex;
  transition: transform 0.5s ease-in-out;
  height: 100%; /* 确保slides高度填满父元素 */
}

.image-slider .slide {
  min-width: 100%;
  box-sizing: border-box;
  height: 100%; /* 确保slide高度填满父元素 */
}

.image-slider .slide img {
  width: 100%;
  height: 100%; /* 确保图片高度填满父元素 */
  object-fit: cover; /* 保持图片的比例 */
  display: block;
  border-radius: 10px 10px 0 0;
}

.image-slider .caption {
  padding: 15px;
  text-align: center;
  font-size: 16px;
  color: #555;
  background-color: #fff;
  border-radius: 0 0 10px 10px;
  box-shadow: 0 -4px 10px rgba(0, 0, 0, 0.1);
}

.image-slider .navigation {
  position: absolute;
  top: 50%;
  width: 100%;
  display: flex;
  justify-content: space-between;
  transform: translateY(-50%);
}

.image-slider .navigation button {
  background-color: rgba(0, 0, 0, 0.5);
  border: none;
  color: white;
  width: 50px; /* 设置按钮的宽度 */
  height: 50px; /* 设置按钮的高度 */
  cursor: pointer;
  border-radius: 50%;
  outline: none;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: background-color 0.3s ease;
}

.image-slider .navigation button:hover {
  background-color: rgba(0, 0, 0, 0.8);
}


</style>
</head>



<body>

  <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/js/bulma-carousel.min.js"></script>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-1 publication-title">Innovative Image Fraud Detection with Cross-Sample Anomaly Analysis: The Power of LLMs</h2>
            <!-- <h3 class="title is-3 publication-title">Visual Instruction Tuning</h3> -->
            <!-- <h5 class="subtitle is-5 publication-awards">NeurIPS 2023 (Oral)</h5> -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a  style="color:#f68946;font-weight:normal;">Qiwen Wang</a>,
              </span>
              <span class="author-block">
                <a  style="color:#008AD7;font-weight:normal;">Junqi Yang</a>,
              </span>
              <span class="author-block">
                <a  style="color:#f68946;font-weight:normal;">Zhenghao Lin</a>,
              </span>
              <span class="author-block">
                <a  style="color:#f68946;font-weight:normal;">Chen Lin<sup>*</sup></a>,
              </span>
              <span class="author-block">
                <a  style="color:#008AD7;font-weight:normal;">Zhenzhe Ying</a>,
              </span>
              <span class="author-block">
                <a  style="color:#008AD7;font-weight:normal;">Weiqiang Wang</a>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> Xiamen University</span>
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> Ant Group</span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block"><sup>*</sup>Corresponding Author</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.10228" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/penguin027/CSIAD" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section"  style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p style="font-family:Times New Roman">
                The financial industry faces a substantial workload in verifying document images. 
                Existing methods based on visual features struggle to identify fraudulent document images due to the lack of visual clues in the tampered regions. 
                This paper proposes <strong>CSIAD</strong> (Cross-Sample Image Anomaly Detection), a novel framework that leverages LLMs to identify logical inconsistencies in semantically similar images. 
                <strong>CSIAD</strong> accurately detects forged images with subtle tampering and provides human-interpretable explanations for each anomaly. 
                Furthermore, we introduce <strong>CrossCred</strong>, a new benchmark of real-world fraudulent document images with fine-grained manual annotations. 
                Experiments demonstrate that <strong>CSIAD</strong> outperforms state-of-the-art image fraud detection methods by <strong>79.6%</strong> (F1) on <strong>CrossCred</strong>, and exceeds deployed industrial solutions by <strong>21.7%</strong> (F1) on real business data.
              </p>
  
          </div>
        </div>
      </div>
        
    </div>
  </section>


 

<section class="section">
  <!-- Results. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"> Introduction </h2>
    </div>
  </div>
  <!-- </div> -->
  <!--/ Results. -->    
<div class="container is-max-desktop">

  <div class="columns is-centered">
    <div class="column is-full-width">
      <centering>
        <div style="text-align: center;">
            <embed src="assets/TaskDefine_new.pdf" type="application/pdf" width="80%" height="600px" />
        </div>
      </centering>    
      <br>
      <div class="content has-text-justified"> 
        <p style="font-family:Times New Roman; text-align: left;">
            Comparison between <strong>TTD</strong> (Tampered Text Detection) and <strong>CSIAD</strong> (Cross-Sample Image Anomaly Detection). The forged image is a mobile payment record.
          <ul type="1">
            <li><b>Left</b>: <span style="font-family:Times New Roman; text-align: left;">Existing <strong>TTD</strong> relies on visual features of a single sample, which struggles with subtle tampering traces.</span></li>
            <li><b>Right</b>: <span style="font-family:Times New Roman; text-align: left;"><strong>CSIAD</strong> incorporates cross-sample analysis based on textual information, effectively increasing the accuracy and explainability of image fraud detection.</span></li>
          </ul>
        </p>
        <p style="font-family:Times New Roman; text-align: left;">
            To better address the limitations of existing image fraud detection datasets in the financial sector, we introduce a new benchmark named <strong>CrossCred</strong>. This dataset is constructed entirely from <strong>real-world</strong> data collected in complex financial fraud scenarios, where document images are carefully forged to evade current detection technologies. <strong>CrossCred</strong> includes detailed human annotations, covering both tampered regions and corresponding explanations.
            Unlike previous datasets that provide only a single sample per case, <strong>CrossCred</strong> supports <em>cross-sample inference</em>: each fraudulent case is linked to a small group of semantically similar images, enabling the evaluation of reasoning-based detection methods. Specifically, from a collection of 400K business images, we mined 109 cross-sample anomaly cases (396 total samples, averaging 3.63 samples per case) and 109 randomly selected anomaly-free images. In total, the benchmark consists of 505 images spanning 61 distinct document types.        
        </p>
        <div style="text-align: center;">
            <embed src="assets/AnnotationCase.pdf" type="application/pdf" width="80%" height="600px" />
            <p style="font-style: italic; font-size: 14px; color: #555; margin-top: 8px;">
              Figure: Examples of the Human Annotation Process.
              Given the LLM's pre-annotated conclusions, human annotators need to determine whether anomalies exist in the actual images and whether the LLM's pre-annotated conclusions align with the ground truth. They then select one of five predefined labels (TP, FP-A, FN, FP-N, TN) to evaluate the LLM's pre-annotated results. If the selected label is FP-A or FN (marked with *), it indicates that the LLM failed to identify the correct anomalous elements, and annotators are required to correct or supplement the anomalous elements along with the associated images. Figures (a), (b), and (c) demonstrate examples of LLM pre-annotated results as TP, FP-A, and FP-N, respectively.
            </p>
        </div> 

        <div style="text-align: center;">
            <embed src="assets/Main.pdf" type="application/pdf" width="80%" height="600px" />
        </div> 
        <p style="font-family:Times New Roman; text-align: left;">
            <strong>Framework for CSIAD.</strong> The diagram outlines the key modules: <em>(a) Retrieval Ensemble</em>, <em>(b) Sample-Specific Rule Generation</em>, <em>(c) Fact-Driven Verification</em>, and <em>(d) Rule-Based Anomaly Analysis</em>.
            To determine whether a document image is fraudulent, a natural workflow is to "consult" relevant images to identify potential anomalies. As illustrated in the framework for <strong>CSIAD</strong>, which consists of four core modules:
            <ul style="margin-top: 0;">
                <li><strong>Retrieval Ensemble:</strong> Given a query image <code>I<sub>q</sub></code>, this module retrieves a batch of relevant images, forming a suspicious set <code>S<sub>q</sub></code>.</li>
                <li><strong>Sample-Specific Rule Generation:</strong> Generates a set of rules <code>R<sub>init</sub></code> that normal samples are expected to follow.</li>
                <li><strong>Fact-Driven Verification:</strong> Validates and filters the rules using factual evidence to yield a refined set <code>R<sub>verified</sub></code>.</li>
                <li><strong>Rule-Based Anomaly Detection:</strong> Uses the verified rules to detect and explain anomalies in <code>S<sub>q</sub></code>.</li>
            </ul>
        </p>
      </div>       
    </div>
  </div>
</section>
  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Examples of VEGA <img id="painting_icon2" width="3%" src="assets/lyra.png"> Dataset</h2>
        <p>All papers in VEGA are from arxiv.</p>
      </div>
    </div>
    <div class="image-slider slider-1">
      <div class="slides">
        <div class="slide">
          <img src="assets/IITC_case1.jpg" alt="IITC Case 1">
          <div class="caption">IITC Case 1</div>
        </div>
        <div class="slide">
          <img src="assets/IITC_case2.jpg" alt="IITC Case 2">
          <div class="caption">IITC Case 2</div>
        </div>
        <div class="slide">
          <img src="assets/ITA_case1.jpg" alt="Image 3">
          <div class="caption">ITA Case 1</div>
        </div>
      </div>
      <div class="navigation">
        <button class="prev">❮</button>
        <button class="next">❯</button>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Specific Cases of VEGA <img id="painting_icon2" width="3%" src="assets/lyra.png"> Models </h2>
        <p>VEGA-8k* is a proprietary model developed using 8k token length VEGA data along with some in-house image-text interleaved data. This in-house data includes a wider range of image-text application scenarios, giving VEGA-8k* a more generalized capability for understanding document. VEGA-Base-4k derived from fine-tuning the Qwen-VL-Chat 7B model using the VEGA dataset with a 4k token length.</p>
      </div>
    </div>
    <div class="image-slider slider-2">
      <div class="slides">
        <div class="slide">
          <img src="assets/VEGA-8k*_case1.png" alt="IITC Case 1">
          <div class="caption">Operation Manual Comprehension Case 1</div>
        </div>
        <div class="slide">
          <img src="assets/VEGA-8k*_case2.png" alt="IITC Case 2">
          <div class="caption">Operation Manual Comprehension Case 2</div>
        </div>
        <div class="slide">
          <img src="assets/VEGA-8k*_case3.png" alt="Image 3">
          <div class="caption">Financial Statement Analysis Case 1</div>
        </div>
        <div class="slide">
          <img src="assets/VEGA-8k*_case4.png" alt="Image 3">
          <div class="caption">Travel Guide Summary Case 1</div>
        </div>
        <div class="slide">
          <img src="assets/VEGA-8k*_case5.png" alt="Image 3">
          <div class="caption">IITC Case 1</div>
        </div>
        <div class="slide">
          <img src="assets/VEGA-8k*_case6.png" alt="Image 3">
          <div class="caption">IITC Case 2</div>
        </div>
      </div>
      <div class="navigation">
        <button class="prev">❮</button>
        <button class="next">❯</button>
      </div>
    </div>
  </div>
</section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@misc{zhou2024vegalearninginterleavedimagetext,
  title={VEGA: Learning Interleaved Image-Text Comprehension in Vision-Language Large Models}, 
  author={Chenyu Zhou and Mengdan Zhang and Peixian Chen and Chaoyou Fu and Yunhang Shen and Xiawu Zheng and Xing Sun and Rongrong Ji},
  year={2024},
  eprint={2406.10228},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2406.10228}, 
}
  </code></pre>
    </div>
  </section>
  
  

  <script>
// document.addEventListener('DOMContentLoaded', () => {
//   // Handle message showing
//   function createChatRow(sender, text, imageSrc) {
//     var article = document.createElement("article");
//     article.className = "media";

//     var figure = document.createElement("figure");
//     figure.className = "media-left";

//     var span = document.createElement("span");
//     span.className = "icon is-large";

//     var icon = document.createElement("i");
//     icon.className = "fas fa-2x" + (sender === "User" ? " fa-user " : sender === "LLaVA" ? " fa-robot" : "");

//     var media = document.createElement("div");
//     media.className = "media-content";

//     var content = document.createElement("div");
//     content.className = "content";

//     var para = document.createElement("p");

//     // wrap text in pre tag to preserve whitespace and line breaks
//     var pre_text = document.createElement("pre");
//     pre_text.style = "background-color: white; font-size: 18px; font-family: Arial; padding: 0; margin: 0; white-space: pre-wrap; word-wrap: break-word;";
//     var paraText = document.createTextNode(text);
//     pre_text.appendChild(paraText);

//     var strong = document.createElement("strong");
//     strong.innerHTML = sender;
//     var br = document.createElement("br");

//     para.appendChild(strong);
//     para.appendChild(br);
//     para.appendChild(pre_text);

//     // Add image if imageSrc is provided
//     if (imageSrc) {
//       var img = document.createElement("img");
//       img.src = imageSrc;
//       img.style = "max-width: 100%; max-height: 300px;"; // Adjust the style as needed
//       para.appendChild(img);
//     }

//     content.appendChild(para);
//     media.appendChild(content);
//     span.appendChild(icon);
//     figure.appendChild(span);
//     if (sender !== "Description") {
//       article.appendChild(figure);
//     }
//     article.appendChild(media);
//     return article;
//   }

//   function addMessageToChatHistory(sender, message, imageSrc) {
//     const chatHistory = document.querySelector('.chat-history');
//     const chatRow = createChatRow(sender, message, imageSrc);
//     chatHistory.appendChild(chatRow);
//     chatHistory.scrollTop = chatHistory.scrollHeight;
//   }

//   function clearChatHistory() {
//     const chatHistory = document.querySelector('.chat-history');
//     chatHistory.innerHTML = "";
//   }

//   // The current image index
//   let currentIndex = 0;

//   // The function to update the displayed chat history
//   function update_dialog_demo() {
//     // Clear the chat history
//     clearChatHistory();

//     for (let i = 0; i < conversations[currentIndex].turns.length; i++) {
//       if (conversations[currentIndex].turns[i].length == 2) {
//         addMessageToChatHistory(conversations[currentIndex].turns[i][0], conversations[currentIndex].turns[i][1]);
//       } else {
//         addMessageToChatHistory(conversations[currentIndex].turns[i][0], conversations[currentIndex].turns[i][1], conversations[currentIndex].turns[i][2]);
//       }
//     }

//     // scroll to the top of the chat history
//     document.querySelector('.chat-history').scrollTop = 0;
//   }

//   // Initialize the displayed image
//   update_dialog_demo();

//   // Event listeners for the buttons
//   document.getElementById('prev-question').addEventListener('click', () => {
//     currentIndex = (currentIndex - 1 + conversations.length) % conversations.length;
//     update_dialog_demo();
//   });

//   document.getElementById('next-question').addEventListener('click', () => {
//     currentIndex = (currentIndex + 1) % conversations.length;
//     update_dialog_demo();
//   });

  // 滑动窗口的代码
  document.addEventListener('DOMContentLoaded', () => {
  function initSlider(sliderClass) {
    const slider = document.querySelector(`.${sliderClass}`);
    const slides = slider.querySelector('.slides');
    const slide = slider.querySelectorAll('.slide');
    let currentSlideIndex = 0;

    slider.querySelector('.next').addEventListener('click', () => {
      currentSlideIndex = (currentSlideIndex + 1) % slide.length;
      updateSlide();
    });

    slider.querySelector('.prev').addEventListener('click', () => {
      currentSlideIndex = (currentSlideIndex - 1 + slide.length) % slide.length;
      updateSlide();
    });

    function updateSlide() {
      slides.style.transform = `translateX(-${currentSlideIndex * 100}%)`;
    }
  }

  initSlider('slider-1');
  initSlider('slider-2');
});


  </script>

</body>

</html>